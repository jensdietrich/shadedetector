\section{Limitations and Threats to Validity}
\label{sec:threats}

The analysis is designed to be precise. This is ensured by making vulnerabilities testable. However, there is a possibility that those tests do not correctly reflect the vulnerability. While sometimes vulnerabilities are reported in great details (for instance, using parser payloads discovered by a fuzzer such as TODO), often reports are vague (and sometimes this is on purpose as part of the disclosure process), and proof-of-concepts are constructed from the understanding of an individual programmer of the vulnerability. However, sometimes those proof-of-concept projects becomes part of the definition of the vulnerability. We therefore think that the possibility of this introducing false positives into our analysis are low. 

Our analysis is unsound by design. As with all program analysis, we have to strike for a reasonable trade-off between precision, scalability and recall, with theoretical and practical limitations implying that an non-trivial analysis that is precise, sound and fast is not possible. Priority was given to precision in line with industry best practices, driven by developer acceptance~\cite{bessey2010few, sadowski2018lessons, distefano2019scaling}.  Scalability considerations had to be taken into account as repositories are very large and evolving, and maintaining a copy is not feasible for economic reasons. Therefore, we have made decisions to limit interactions with  the Maven repositories via the REST API by limiting the number of queries. While some of this can be achieved by engineering (in particular, our tool extensively uses caching, similar to what other Maven clients do) , sometimes those restrictions (number of classes used to detect clone candidates, number of results and pages fetched for each query) imply that results are missed. 

We are not in a position to quantify this at this stage, but expect diminishing returns if more resources were allocated to run the analysis.  We think that that the proposed analysis is still useful as its purpose is not not measure the number of artifacts associated with vulnerabilities, but to demonstrate that this is a significant problem that deserves attention.

A limitation of our analysis is that it relies on source code. This means that components written in other languages that can be compiled into Java bytecode and deployed in the Maven repository are not covered, and this decreases the detection rate of our tool. This problem can be addressed in future work by writing a source-code based clone analysis for the respective languages, or by switching to a bytecode-based method that can abstract from compiler specifics~\cite{dann2019sootdiff}. 



 

 

